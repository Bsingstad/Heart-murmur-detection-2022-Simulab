{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRmi1FbhCDW0",
        "outputId": "a74073c7-3529-412f-a255-8662c4b99284"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 29.4 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython) (4.1.1)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.27 gitdb-4.0.9 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BQL6lPD0CVgh"
      },
      "outputs": [],
      "source": [
        "HTTPS_REMOTE_URL = 'https://github.com/Bsingstad/Heart-murmur-detection-2022-Simulab.git'\n",
        "DEST_NAME = 'heart_murmurs'\n",
        "cloned_repo = Repo.clone_from(HTTPS_REMOTE_URL, DEST_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBMgQeTjCkuf",
        "outputId": "8b63b1e8-546b-4c4c-a85d-1eb636cb8000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=02253d033c60476c11e2d477487ccaa7d14b6557b17fabd0f1a262877ba0a2e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQuh1VhrC39v",
        "outputId": "ef7679c7-32bd-47d3-bc54-2f2eb8454fc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n",
            "/bin/bash: -c: line 0: unexpected EOF while looking for matching `''\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW10TQKSC1MW",
        "outputId": "29ea0b73-6b62-43ed-f9da-153299564c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading the-circor-digiscope-phonocardiogram-dataset-v2.zip to /content\n",
            " 99% 445M/449M [00:06<00:00, 130MB/s]\n",
            "100% 449M/449M [00:06<00:00, 71.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d bjoernjostein/the-circor-digiscope-phonocardiogram-dataset-v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uiitcpLxDBWm"
      },
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "try:\n",
        "  os.mkdir(\"/content/data/\")\n",
        "except:\n",
        "  print(\"data folder allready exists\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nKKUjHdSQqym"
      },
      "outputs": [],
      "source": [
        "import os, zipfile\n",
        "\n",
        "dir_name = \"/content/\"\n",
        "target_dir = \"/content/data/\"\n",
        "extension = \".zip\"\n",
        " \n",
        "os.chdir(dir_name) # change directory from working dir to dir with files\n",
        "\n",
        "for item in os.listdir(dir_name): # loop through items in dir\n",
        "    if item.endswith(extension): # check for \".zip\" extension\n",
        "        file_name = os.path.abspath(item) # get full path of files\n",
        "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
        "        zip_ref.extractall(target_dir) # extract file to dir\n",
        "        zip_ref.close() # close file\n",
        "        os.remove(file_name) # delete zipped file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWiDsltwE-rg"
      },
      "outputs": [],
      "source": [
        "os.mknod(\"/content/heart_murmurs/__init__.py\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "H4vxg6fhmoLP"
      },
      "outputs": [],
      "source": [
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    out = open(file_name, 'w')\n",
        "    out.writelines(lines)\n",
        "    out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5QunscIlmr3y"
      },
      "outputs": [],
      "source": [
        "replace_line('/content/heart_murmurs/run_model.py',12,\"from .helper_code import * \\n\")\n",
        "replace_line('/content/heart_murmurs/run_model.py',13,\"from .team_code import load_challenge_model, run_challenge_model \\n\")\n",
        "replace_line('/content/heart_murmurs/cross_validate.py',15,\"from .helper_code import * \\n\")\n",
        "replace_line('/content/heart_murmurs/evaluate_model.py',16,\"from .helper_code import load_patient_data, get_murmur, get_outcome, load_challenge_outputs, compare_strings \\n\")\n",
        "replace_line('/content/heart_murmurs/cross_validate.py',16,\"from .team_code import base_model, load_challenge_model, build_murmur_model, build_clinical_model, scheduler, scheduler_2, get_murmur_locations, pad_array, calculating_class_weights \\n\")\n",
        "replace_line('/content/heart_murmurs/team_code.py',11,\"from .helper_code import * \\n\")\n",
        "replace_line('/content/heart_murmurs/train_model.py',11,\"from .helper_code import is_integer \\n\")\n",
        "replace_line('/content/heart_murmurs/train_model.py',12,\"from .team_code import train_challenge_model \\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1o9J_FbaGCxu"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload\n",
        "%reload_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eVbI2ZbZDyWA"
      },
      "outputs": [],
      "source": [
        "from heart_murmurs.helper_code import *\n",
        "\n",
        "# have to add a \".\" in from of the module imports (in the scrips:train_model, run_model and team_code )\n",
        "from heart_murmurs.train_model import *\n",
        "from heart_murmurs.run_model import *\n",
        "from heart_murmurs.team_code import *\n",
        "from heart_murmurs.evaluate_model import *\n",
        "from heart_murmurs.cross_validate import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "AxvEca5vsn53"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  os.mkdir(\"/content/results/\")\n",
        "except:\n",
        "  print(\"results folder allreadu exists\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_challenge_model(\"/content/data/training_data/training_data/\", \"/content/models/\", 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmtD4-izCLST",
        "outputId": "3b116a4a-4b48-4449-aec1-599572ed6fed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding data files...\n",
            "Extracting features and labels from the Challenge data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 942/942 [00:20<00:00, 46.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of signals = 3163\n",
            "Murmurs prevalence:\n",
            "Present = 616, Unknown = 156, Absent = 2391\n",
            "Outcomes prevalence:\n",
            "Abnormal = 1531, Normal = 1632\n",
            "Epoch 1/30\n",
            "159/159 [==============================] - 96s 468ms/step - loss: 1.5986 - categorical_accuracy: 0.3301 - auc_1: 0.5626\n",
            "Epoch 2/30\n",
            "159/159 [==============================] - 78s 493ms/step - loss: 1.5392 - categorical_accuracy: 0.3566 - auc_1: 0.5878\n",
            "Epoch 3/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.5072 - categorical_accuracy: 0.4021 - auc_1: 0.6182\n",
            "Epoch 4/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4967 - categorical_accuracy: 0.4031 - auc_1: 0.6183\n",
            "Epoch 5/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4540 - categorical_accuracy: 0.4195 - auc_1: 0.6430\n",
            "Epoch 6/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4511 - categorical_accuracy: 0.3863 - auc_1: 0.6220\n",
            "Epoch 7/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4283 - categorical_accuracy: 0.4344 - auc_1: 0.6574\n",
            "Epoch 8/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4430 - categorical_accuracy: 0.4195 - auc_1: 0.6425\n",
            "Epoch 9/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4397 - categorical_accuracy: 0.3892 - auc_1: 0.6296\n",
            "Epoch 10/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4417 - categorical_accuracy: 0.4047 - auc_1: 0.6402\n",
            "Epoch 11/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4495 - categorical_accuracy: 0.4186 - auc_1: 0.6436\n",
            "Epoch 12/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4332 - categorical_accuracy: 0.4410 - auc_1: 0.6574\n",
            "Epoch 13/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4331 - categorical_accuracy: 0.4230 - auc_1: 0.6504\n",
            "Epoch 14/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4336 - categorical_accuracy: 0.4451 - auc_1: 0.6671\n",
            "Epoch 15/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4221 - categorical_accuracy: 0.4246 - auc_1: 0.6490\n",
            "Epoch 16/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.3846 - categorical_accuracy: 0.4470 - auc_1: 0.6669\n",
            "Epoch 17/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.4886 - categorical_accuracy: 0.4546 - auc_1: 0.6596\n",
            "Epoch 18/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4137 - categorical_accuracy: 0.4584 - auc_1: 0.6695\n",
            "Epoch 19/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.3858 - categorical_accuracy: 0.4483 - auc_1: 0.6666\n",
            "Epoch 20/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4278 - categorical_accuracy: 0.4423 - auc_1: 0.6589\n",
            "Epoch 21/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.4236 - categorical_accuracy: 0.4540 - auc_1: 0.6606\n",
            "Epoch 22/30\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 1.5800 - categorical_accuracy: 0.3911 - auc_1: 0.6008\n",
            "Epoch 23/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6419 - categorical_accuracy: 0.2833 - auc_1: 0.5362\n",
            "Epoch 24/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6436 - categorical_accuracy: 0.3607 - auc_1: 0.5169\n",
            "Epoch 25/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.5866 - categorical_accuracy: 0.3645 - auc_1: 0.5702\n",
            "Epoch 26/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6066 - categorical_accuracy: 0.3667 - auc_1: 0.5671\n",
            "Epoch 27/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.5729 - categorical_accuracy: 0.3351 - auc_1: 0.5625\n",
            "Epoch 28/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6318 - categorical_accuracy: 0.3509 - auc_1: 0.5382\n",
            "Epoch 29/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6312 - categorical_accuracy: 0.3250 - auc_1: 0.5548\n",
            "Epoch 30/30\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 1.6001 - categorical_accuracy: 0.3380 - auc_1: 0.5509\n",
            "Epoch 1/20\n",
            "159/159 [==============================] - 88s 499ms/step - loss: 0.6691 - binary_accuracy: 0.5239 - auc: 0.5293\n",
            "Epoch 2/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6665 - binary_accuracy: 0.5438 - auc: 0.5479\n",
            "Epoch 3/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6665 - binary_accuracy: 0.5432 - auc: 0.5517\n",
            "Epoch 4/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6642 - binary_accuracy: 0.5555 - auc: 0.5553\n",
            "Epoch 5/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6598 - binary_accuracy: 0.5612 - auc: 0.5657\n",
            "Epoch 6/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6621 - binary_accuracy: 0.5485 - auc: 0.5603\n",
            "Epoch 7/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6571 - binary_accuracy: 0.5612 - auc: 0.5798\n",
            "Epoch 8/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6559 - binary_accuracy: 0.5615 - auc: 0.5823\n",
            "Epoch 9/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6506 - binary_accuracy: 0.5694 - auc: 0.5953\n",
            "Epoch 10/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6511 - binary_accuracy: 0.5839 - auc: 0.6032\n",
            "Epoch 11/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6446 - binary_accuracy: 0.5846 - auc: 0.6130\n",
            "Epoch 12/20\n",
            "159/159 [==============================] - 79s 497ms/step - loss: 0.6456 - binary_accuracy: 0.5833 - auc: 0.6166\n",
            "Epoch 13/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6422 - binary_accuracy: 0.5868 - auc: 0.6188\n",
            "Epoch 14/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6449 - binary_accuracy: 0.5855 - auc: 0.6186\n",
            "Epoch 15/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6387 - binary_accuracy: 0.5928 - auc: 0.6259\n",
            "Epoch 16/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6411 - binary_accuracy: 0.5887 - auc: 0.6244\n",
            "Epoch 17/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6315 - binary_accuracy: 0.5960 - auc: 0.6391\n",
            "Epoch 18/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6319 - binary_accuracy: 0.6061 - auc: 0.6410\n",
            "Epoch 19/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6273 - binary_accuracy: 0.6089 - auc: 0.6480\n",
            "Epoch 20/20\n",
            "159/159 [==============================] - 79s 498ms/step - loss: 0.6278 - binary_accuracy: 0.6187 - auc: 0.6559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  os.mkdir(\"/content/output/\")\n",
        "except:\n",
        "  print(\"output folder allready exist..\")"
      ],
      "metadata": {
        "id": "BekYnV7PCZhS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(\"/content/models/\", \"/content/data/training_data/training_data/\", \"/content/output/\", allow_failures=True, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt78LmzuCizo",
        "outputId": "21b75b4b-136e-4361-ebca-f24c3f1b7989"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Challenge model...\n",
            "Running model on Challenge data...\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(\"/content/data/training_data/training_data/\", \"/content/output/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nndqnLY1Cm9e",
        "outputId": "3512236a-096b-460a-88b9-bec4000422b7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((['Present', 'Unknown', 'Absent'],\n",
              "  0.6804151828425304,\n",
              "  0.4702572951978157,\n",
              "  array([0.58206726, 0.82765177, 0.63152652]),\n",
              "  array([0.29307197, 0.29034393, 0.82735598]),\n",
              "  0.14784495439835246,\n",
              "  array([0.29126214, 0.15227273, 0.        ]),\n",
              "  0.11889596602972399,\n",
              "  array([0.25139665, 0.98529412, 0.        ]),\n",
              "  0.23745819397993312,\n",
              "  14850.764331210192),\n",
              " (['Abnormal', 'Normal'],\n",
              "  0.25107844198974827,\n",
              "  0.3598379792441495,\n",
              "  array([0.25107844, 0.25107844]),\n",
              "  array([0.34784419, 0.37183176]),\n",
              "  0.6128029361797758,\n",
              "  array([0.68226823, 0.54333765]),\n",
              "  0.6252653927813163,\n",
              "  array([0.83114035, 0.43209877]),\n",
              "  0.7610267534345625,\n",
              "  10231.32665420016))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqQDko6vRvcl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "execute_training_pipeline.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('moody_tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "74583c63aac1e7f106966fcb7023fdbc6cc518817ac509f557e16d75a606cf95"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}